{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Labor 1\n",
        "\n",
        "A párhuzamos programozás olyan programozási paradigma, amely lehetővé teszi, hogy egyidejűleg több feladatot hajtson végre egy számítógép vagy több számítógép egyszerre. A párhuzamos programozás lehetővé teszi a számítási teljesítmény növelését, a nagyobb vagy bonyolultabb számítási feladatok megoldását.\n",
        "\n",
        "A [GPGPU](https://www.gigabyte.com/Glossary/gpgpu) rövidítés a \"General Purpose Graphics Processing Unit\"-ra utal, ami egy olyan számítási technológia, amely során a grafikus kártyák (GPU-k) számítási kapacitását használjuk általános célú számítások végrehajtására. A GPU-k eredetileg kifejezetten grafikus feladatok hatékony megoldására lettek tervezve, mint például a képfeldolgozás vagy 3D grafika. Azonban, az elmúlt években a GPU-k egyre inkább beépültek az általános célú számítások világába is.\n",
        "\n",
        "A GPGPU technológia alkalmazása lehetővé teszi, hogy a GPU-k nagy számítási kapacitását felhasználják olyan feladatok elvégzésére, mint például a gépi tanulás, a kriptográfiai műveletek, a tudományos szimulációk vagy a nagy adathalmazok feldolgozása. A GPGPU technológia használata jelentősen felgyorsíthatja ezeket a számítási feladatokat, és csökkentheti azok elvégzésének idejét.\n",
        "\n",
        "## CUDA Runtime API\n",
        "\n",
        "\n",
        "A [CUDA Runtime API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html) egy függvénykönyvtárból és a C++ szintaxis egyszerű kiegészítéséből áll.\n",
        "\n",
        "A CUDA programokat `*.cu` (nem `*.c` vagy `*.cpp`) kiterjesztésű állományokban írjuk. Mint meglátjuk, alapvetően C++ kódot írunk, melyet néha kiegészíthetünk gyorsítón futtatandó programrészletekkel, úgynevezett \"CUDA kernelekkel\".\n",
        "\n",
        "Az alábbi kódrészlet egy tökéletesen működő CUDA program, csak éppenséggel még nem tartalmaz gyorsító specifikus kódot.\n",
        "\n",
        "```cpp\n",
        "#include <iostream>\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    std::cout << \"Hello World!\" << std::endl;\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "Ha a programunkban szeretnénk kihasználni a GPU számítási kapacitását lehetőségeit is, akkor GPU kódot is írnunk kell. Ez a számításokhoz szükséges adatokat előkészíti, átmásolja, meghívja a GPU kernelt, majd az adatokat visszamásolja. A CUDA forráskódok általában keverten tartalmazzák a CPU, és GPU kódokat.\n",
        "\n",
        "A GPU-n futó számítást úgynevezett a fentebb említett kernel függvények megadásával tudjuk megvalósítani. Ezek a `__global__` előtaggal rendelkező függvények.\n",
        "\n",
        "### Kompilálás és futtatás\n",
        "\n",
        "A CUDA (`*.cu` kiterjesztésű) programjaink kompilálásához, használjuk a következő parancsot:  \n",
        "\n",
        "```\n",
        "!nvcc mysurcefile.cu -o programname\n",
        "```\n",
        "\n",
        "majd sikeres kompilálás esetében, futtatáshoz:\n",
        "```\n",
        "!./programname\n",
        "```"
      ],
      "metadata": {
        "id": "ikVGiziWBV53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vUP6bz3eCzMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colaboratory\n",
        "\n",
        "A Google Colaboratory (röviden Colab) egy ingyenes online platform, amely lehetővé teszi a felhasználók számára a (főleg) Python programozási nyelv interaktív környezetében történő munkavégzését. Az egyik fő előnye, hogy ingyenes GPU és TPU (Tensor Processing Unit) számítási erőforrásokat biztosít a felhasználók számára, azzal a cállal, hogy lehetővé tegye a nagyobb adatméretű és bonyolultabb gépi tanulási és adatelemzési feladatok végrehajtását.\n",
        "\n",
        "Az GPU erőforrások igénybevétele érdekében, a felhasználóknak a futásidejű környezet típusát kell áttálítsa. Ehhez, a `Runtime/Change runtime` menűpontban válasszuk ki, hogy `GPU`. "
      ],
      "metadata": {
        "id": "RDNbKVlU9cMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `GPU` elérhetőségét tesztelni tudjuk a következő kóddal: "
      ],
      "metadata": {
        "id": "LH1eSOFi_g_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j03fCHP_PoQ",
        "outputId": "d390abd9-6a97-48e8-9a00-3780e70701ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Nvidia kompájler verziójának lekérése:"
      ],
      "metadata": {
        "id": "SxGnDTAs_51e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hxdSMs37ZtV",
        "outputId": "7738f92a-89c8-4844-f89f-33e67eae1e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Tue_Mar__8_18:18:20_PST_2022\n",
            "Cuda compilation tools, release 11.6, V11.6.124\n",
            "Build cuda_11.6.r11.6/compiler.31057947_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A kód cellákkban csak Python kód futtatható direkt modon. Ezért, [%%writefile magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) parancsal fogjuk kiírni a lemezre a programjainkat, majd ezeket más kódcellákban kompiláljuk és futtatjuk.\n",
        "\n",
        "Például, az alábbi példaprogram GPU-n végzi el két szám összeadását."
      ],
      "metadata": {
        "id": "6BAs6WrnAA7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vecadd.cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void add(int a, int b, int* c)\n",
        "{\n",
        "    *c = a + b;\n",
        "    return;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    int c;\n",
        "    int* dev_c;\n",
        "\t\n",
        "\t//memória foglalás a GPU-n\n",
        "    cudaMalloc((void**) &dev_c, sizeof(int));\n",
        "\n",
        "    add<<<1,1>>>(1, 2, dev_c);\n",
        "\n",
        "    cudaMemcpy(&c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"a + b = %d\\n\", c);\n",
        "    \n",
        "    //lefolglat memória felszabadítása\n",
        "    cudaFree(dev_c);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9JO5bt7hrW",
        "outputId": "28c0c1ae-93bc-47f4-af9e-f33a9488e7c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "És íme meg is jelenik a `vecadd.cu` állomány:"
      ],
      "metadata": {
        "id": "um6CYayyAxIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsq0-uVN9Gbo",
        "outputId": "b0477aeb-bb1e-45f8-9686-430530909210"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kompilálás:"
      ],
      "metadata": {
        "id": "lPeatuhnA6Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vecadd.cu"
      ],
      "metadata": {
        "id": "B8gcA_rP9Lrg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ellenörizzük ha megjelent a futtatható bináris program (`a.out`):"
      ],
      "metadata": {
        "id": "HBKgJTrFA-Yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0qF_LNk9P_I",
        "outputId": "13a17055-daa3-4e7e-e71b-952a6710c3c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.out  sample_data  vecadd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Futtatás:"
      ],
      "metadata": {
        "id": "0GJCibQSBJer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lngC1HH79R7N",
        "outputId": "dde55ef2-4bf8-4ed5-ed85-865bb1d45213"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b = 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feladatok\n",
        "\n",
        "1. Írjunk egy CUDA programot, mely a [`cudaError_t cudaGetDeviceCount (int * count)`](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g18808e54893cfcaafefeab31a73cc55f), [`cudaError_t cudaGetDeviceProperties (struct cudaDeviceProp * prop, int device )`](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0) függvények segítségével, kiírja a Rocks szerveren található CUDA kompatibilis GPU főbb paramétereit.\n",
        "A jellemzőket tartalmazó `cudaDeviceProp` struktúra definíciója a következő:\n",
        "\n",
        "  ```cpp\n",
        "  struct cudaDeviceProp {\n",
        "                char name[256];\n",
        "                cudaUUID_t uuid;\n",
        "                size_t totalGlobalMem;\n",
        "                size_t sharedMemPerBlock;\n",
        "                int regsPerBlock;\n",
        "                int warpSize;\n",
        "                size_t memPitch;\n",
        "                int maxThreadsPerBlock;\n",
        "                int maxThreadsDim[3];\n",
        "                int maxGridSize[3];\n",
        "                int clockRate;\n",
        "                size_t totalConstMem;\n",
        "                int major;\n",
        "                int minor;\n",
        "                size_t textureAlignment;\n",
        "                size_t texturePitchAlignment;\n",
        "                int deviceOverlap;\n",
        "                int multiProcessorCount;\n",
        "                int kernelExecTimeoutEnabled;\n",
        "                int integrated;\n",
        "                int canMapHostMemory;\n",
        "                int computeMode;\n",
        "                int maxTexture1D;\n",
        "                int maxTexture1DMipmap;\n",
        "                int maxTexture1DLinear;\n",
        "                int maxTexture2D[2];\n",
        "                int maxTexture2DMipmap[2];\n",
        "                int maxTexture2DLinear[3];\n",
        "                int maxTexture2DGather[2];\n",
        "                int maxTexture3D[3];\n",
        "                int maxTexture3DAlt[3];\n",
        "                int maxTextureCubemap;\n",
        "                int maxTexture1DLayered[2];\n",
        "                int maxTexture2DLayered[3];\n",
        "                int maxTextureCubemapLayered[2];\n",
        "                int maxSurface1D;\n",
        "                int maxSurface2D[2];\n",
        "                int maxSurface3D[3];\n",
        "                int maxSurface1DLayered[2];\n",
        "                int maxSurface2DLayered[3];\n",
        "                int maxSurfaceCubemap;\n",
        "                int maxSurfaceCubemapLayered[2];\n",
        "                size_t surfaceAlignment;\n",
        "                int concurrentKernels;\n",
        "                int ECCEnabled;\n",
        "                int pciBusID;\n",
        "                int pciDeviceID;\n",
        "                int pciDomainID;\n",
        "                int tccDriver;\n",
        "                int asyncEngineCount;\n",
        "                int unifiedAddressing;\n",
        "                int memoryClockRate;\n",
        "                int memoryBusWidth;\n",
        "                int l2CacheSize;\n",
        "                int persistingL2CacheMaxSize;\n",
        "                int maxThreadsPerMultiProcessor;\n",
        "                int streamPrioritiesSupported;\n",
        "                int globalL1CacheSupported;\n",
        "                int localL1CacheSupported;\n",
        "                size_t sharedMemPerMultiprocessor;\n",
        "                int regsPerMultiprocessor;\n",
        "                int managedMemory;\n",
        "                int isMultiGpuBoard;\n",
        "                int multiGpuBoardGroupID;\n",
        "                int singleToDoublePrecisionPerfRatio;\n",
        "                int pageableMemoryAccess;\n",
        "                int concurrentManagedAccess;\n",
        "                int computePreemptionSupported;\n",
        "                int canUseHostPointerForRegisteredMem;\n",
        "                int cooperativeLaunch;\n",
        "                int cooperativeMultiDeviceLaunch;\n",
        "                int pageableMemoryAccessUsesHostPageTables;\n",
        "                int directManagedMemAccessFromHost;\n",
        "                int accessPolicyMaxWindowSize;\n",
        "            }\n",
        "   ```\n",
        "\n",
        "2. Írjunk egy \"Hello, World\" CUDA kernelt, melyben minden szál kiírja az [egyedi azonosítóját](https://blog.usejournal.com/cuda-thread-indexing-fb9910cba084). Hívjuk meg a kernelt különböző rács és blokk konfigurációkkal. Használjuk a [cudaError_t cudaDeviceSynchronize ( void )](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d) függvényt a kernel hívás bevárására.\n"
      ],
      "metadata": {
        "id": "xnd_G4H09VNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. feladat megoldása"
      ],
      "metadata": {
        "id": "yMJdvA-ci3Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deviceProps.cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    int deviceId;\n",
        "    cudaGetDevice(&deviceId);\n",
        "\n",
        "    cudaDeviceProp props;\n",
        "    cudaGetDeviceProperties(&props, deviceId);\n",
        "\n",
        "    char *deviceName = props.name;\n",
        "    int computeCapabilityMajor = props.major;\n",
        "    int computeCapabilityMinor = props.minor;\n",
        "    int multiProcessorCount = props.multiProcessorCount;\n",
        "    int warpSize = props.warpSize;\n",
        "\n",
        "    printf(\"Device name: %s\\nDevice ID: %d\\nNumber of SMs: %d\\nCompute Capability Major: %d\\nCompute Capability Minor: %d\\nWarp Size: %d\\n\", deviceName, deviceId, multiProcessorCount, computeCapabilityMajor, computeCapabilityMinor, warpSize);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "FgeftCMSkLJh",
        "outputId": "cc6f1f5d-6174-4dd9-e67b-9d955e93ffe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting deviceProps.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc deviceProps.cu -o deviceProps -run"
      ],
      "metadata": {
        "id": "AsooqoaCk2Ye",
        "outputId": "30a95fed-529d-454b-d137-ad47809c3964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device name: Tesla T4\n",
            "Device ID: 0\n",
            "Number of SMs: 40\n",
            "Compute Capability Major: 7\n",
            "Compute Capability Minor: 5\n",
            "Warp Size: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. feladat megoldás"
      ],
      "metadata": {
        "id": "rahAVerGi38_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helloWorld.cu\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void helloWorld()\n",
        "{\n",
        "    printf(\"Block id: %d -- Thread id: %d\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        "    helloWorld<<<1,5>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    helloWorld<<<8,16>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "nshRJrmCiU0j",
        "outputId": "3850fb2b-cab7-4b79-d6c6-283f5dcb8b9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting helloWorld.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc helloWorld.cu -o helloWorld -run"
      ],
      "metadata": {
        "id": "2QX67J3DjD_Y",
        "outputId": "fd77d25e-05b9-41d3-c94f-b5adf4ea8427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block id: 0 -- Thread id: 0\n",
            "Block id: 0 -- Thread id: 1\n",
            "Block id: 0 -- Thread id: 2\n",
            "Block id: 0 -- Thread id: 3\n",
            "Block id: 0 -- Thread id: 4\n",
            "Block id: 0 -- Thread id: 0\n",
            "Block id: 0 -- Thread id: 1\n",
            "Block id: 0 -- Thread id: 2\n",
            "Block id: 0 -- Thread id: 3\n",
            "Block id: 0 -- Thread id: 4\n",
            "Block id: 0 -- Thread id: 5\n",
            "Block id: 0 -- Thread id: 6\n",
            "Block id: 0 -- Thread id: 7\n",
            "Block id: 0 -- Thread id: 8\n",
            "Block id: 0 -- Thread id: 9\n",
            "Block id: 0 -- Thread id: 10\n",
            "Block id: 0 -- Thread id: 11\n",
            "Block id: 0 -- Thread id: 12\n",
            "Block id: 0 -- Thread id: 13\n",
            "Block id: 0 -- Thread id: 14\n",
            "Block id: 0 -- Thread id: 15\n",
            "Block id: 5 -- Thread id: 0\n",
            "Block id: 5 -- Thread id: 1\n",
            "Block id: 5 -- Thread id: 2\n",
            "Block id: 5 -- Thread id: 3\n",
            "Block id: 5 -- Thread id: 4\n",
            "Block id: 5 -- Thread id: 5\n",
            "Block id: 5 -- Thread id: 6\n",
            "Block id: 5 -- Thread id: 7\n",
            "Block id: 5 -- Thread id: 8\n",
            "Block id: 5 -- Thread id: 9\n",
            "Block id: 5 -- Thread id: 10\n",
            "Block id: 5 -- Thread id: 11\n",
            "Block id: 5 -- Thread id: 12\n",
            "Block id: 5 -- Thread id: 13\n",
            "Block id: 5 -- Thread id: 14\n",
            "Block id: 5 -- Thread id: 15\n",
            "Block id: 6 -- Thread id: 0\n",
            "Block id: 6 -- Thread id: 1\n",
            "Block id: 6 -- Thread id: 2\n",
            "Block id: 6 -- Thread id: 3\n",
            "Block id: 6 -- Thread id: 4\n",
            "Block id: 6 -- Thread id: 5\n",
            "Block id: 6 -- Thread id: 6\n",
            "Block id: 6 -- Thread id: 7\n",
            "Block id: 6 -- Thread id: 8\n",
            "Block id: 6 -- Thread id: 9\n",
            "Block id: 6 -- Thread id: 10\n",
            "Block id: 6 -- Thread id: 11\n",
            "Block id: 6 -- Thread id: 12\n",
            "Block id: 6 -- Thread id: 13\n",
            "Block id: 6 -- Thread id: 14\n",
            "Block id: 6 -- Thread id: 15\n",
            "Block id: 1 -- Thread id: 0\n",
            "Block id: 1 -- Thread id: 1\n",
            "Block id: 1 -- Thread id: 2\n",
            "Block id: 1 -- Thread id: 3\n",
            "Block id: 1 -- Thread id: 4\n",
            "Block id: 1 -- Thread id: 5\n",
            "Block id: 1 -- Thread id: 6\n",
            "Block id: 1 -- Thread id: 7\n",
            "Block id: 1 -- Thread id: 8\n",
            "Block id: 1 -- Thread id: 9\n",
            "Block id: 1 -- Thread id: 10\n",
            "Block id: 1 -- Thread id: 11\n",
            "Block id: 1 -- Thread id: 12\n",
            "Block id: 1 -- Thread id: 13\n",
            "Block id: 1 -- Thread id: 14\n",
            "Block id: 1 -- Thread id: 15\n",
            "Block id: 4 -- Thread id: 0\n",
            "Block id: 4 -- Thread id: 1\n",
            "Block id: 4 -- Thread id: 2\n",
            "Block id: 4 -- Thread id: 3\n",
            "Block id: 4 -- Thread id: 4\n",
            "Block id: 4 -- Thread id: 5\n",
            "Block id: 4 -- Thread id: 6\n",
            "Block id: 4 -- Thread id: 7\n",
            "Block id: 4 -- Thread id: 8\n",
            "Block id: 4 -- Thread id: 9\n",
            "Block id: 4 -- Thread id: 10\n",
            "Block id: 4 -- Thread id: 11\n",
            "Block id: 4 -- Thread id: 12\n",
            "Block id: 4 -- Thread id: 13\n",
            "Block id: 4 -- Thread id: 14\n",
            "Block id: 4 -- Thread id: 15\n",
            "Block id: 7 -- Thread id: 0\n",
            "Block id: 7 -- Thread id: 1\n",
            "Block id: 7 -- Thread id: 2\n",
            "Block id: 7 -- Thread id: 3\n",
            "Block id: 7 -- Thread id: 4\n",
            "Block id: 7 -- Thread id: 5\n",
            "Block id: 7 -- Thread id: 6\n",
            "Block id: 7 -- Thread id: 7\n",
            "Block id: 7 -- Thread id: 8\n",
            "Block id: 7 -- Thread id: 9\n",
            "Block id: 7 -- Thread id: 10\n",
            "Block id: 7 -- Thread id: 11\n",
            "Block id: 7 -- Thread id: 12\n",
            "Block id: 7 -- Thread id: 13\n",
            "Block id: 7 -- Thread id: 14\n",
            "Block id: 7 -- Thread id: 15\n",
            "Block id: 2 -- Thread id: 0\n",
            "Block id: 2 -- Thread id: 1\n",
            "Block id: 2 -- Thread id: 2\n",
            "Block id: 2 -- Thread id: 3\n",
            "Block id: 2 -- Thread id: 4\n",
            "Block id: 2 -- Thread id: 5\n",
            "Block id: 2 -- Thread id: 6\n",
            "Block id: 2 -- Thread id: 7\n",
            "Block id: 2 -- Thread id: 8\n",
            "Block id: 2 -- Thread id: 9\n",
            "Block id: 2 -- Thread id: 10\n",
            "Block id: 2 -- Thread id: 11\n",
            "Block id: 2 -- Thread id: 12\n",
            "Block id: 2 -- Thread id: 13\n",
            "Block id: 2 -- Thread id: 14\n",
            "Block id: 2 -- Thread id: 15\n",
            "Block id: 3 -- Thread id: 0\n",
            "Block id: 3 -- Thread id: 1\n",
            "Block id: 3 -- Thread id: 2\n",
            "Block id: 3 -- Thread id: 3\n",
            "Block id: 3 -- Thread id: 4\n",
            "Block id: 3 -- Thread id: 5\n",
            "Block id: 3 -- Thread id: 6\n",
            "Block id: 3 -- Thread id: 7\n",
            "Block id: 3 -- Thread id: 8\n",
            "Block id: 3 -- Thread id: 9\n",
            "Block id: 3 -- Thread id: 10\n",
            "Block id: 3 -- Thread id: 11\n",
            "Block id: 3 -- Thread id: 12\n",
            "Block id: 3 -- Thread id: 13\n",
            "Block id: 3 -- Thread id: 14\n",
            "Block id: 3 -- Thread id: 15\n"
          ]
        }
      ]
    }
  ]
}